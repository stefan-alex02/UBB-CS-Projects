{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pBJxByFeqDe",
        "outputId": "20f72dfe-1261-4a01-84d9-e9ab3efca5ff"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JJ5ClmYEeNs"
      },
      "source": [
        "# Definirea problemei\n",
        "Ce se dă:\n",
        "\n",
        "Setul de date este dat, inclusiv patru directoare care conțin imagini:\n",
        "monet_tfrec și monet_jpg: conțin 300 de imagini ale picturilor lui Monet, fie în formatul TFRecord, fie în formatul JPEG.\n",
        "photo_tfrec și photo_jpg: conțin 7028 de fotografii, fie în formatul TFRecord, fie în formatul JPEG.\n",
        "Ce se cere:\n",
        "\n",
        "Se cere să se dezvolte un algoritm care să preia imaginile din directoarele photo_tfrec și photo_jpg (input), să le proceseze pentru a adăuga stilul lui Monet și să genereze imaginile corespunzătoare în stilul Monet.\n",
        "Outputul algoritmului trebuie să fie imaginile generate în stilul Monet, care trebuie să fie salvate în format JPEG și să fie împachetate într-un fișier zip.\n",
        "\n",
        "Tip problema: Generative Adversarial Networks - care are la baza doua retele neuronale, una care genereaza continut si una care care incearca sa distinga intre materialele reale si cele generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9OVMuEmaT1K"
      },
      "source": [
        "# Analiza exploratorie a datelor (imagini)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr3f3EXTEZ_z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYdtA_vvHgUN"
      },
      "source": [
        "Definirea directoarelor pentru date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaqLw034Hj3L"
      },
      "outputs": [],
      "source": [
        "monet_tfrec_dir = '/content/drive/MyDrive/data/monet_tfrec'\n",
        "photo_tfrec_dir = '/content/drive/MyDrive/data/photo_tfrec'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0KOCDy1Hqza"
      },
      "source": [
        "\n",
        "Funcție pentru a încărca și decoda imagini din formatul TFRecord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLVLyoz_HqVx"
      },
      "outputs": [],
      "source": [
        "def decode_tfrecord(example):\n",
        "    tfrecord_format = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtzEouJ7H14j"
      },
      "source": [
        "\n",
        "Funcție pentru a număra imaginile dintr-un director TFRecord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PabQBKAyH2Nf"
      },
      "outputs": [],
      "source": [
        "def count_tfrecord_files(tfrecord_dir):\n",
        "    return sum([len(files) for _, _, files in os.walk(tfrecord_dir)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKRm0Q71H8HG"
      },
      "source": [
        "\n",
        "Numărul de imagini din fiecare director TFRecord, numărul de imagini JPEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNbcVfMSH9j1"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_monet_images = count_tfrecord_files(monet_tfrec_dir)\n",
        "num_photo_images = count_tfrecord_files(photo_tfrec_dir)\n",
        "\n",
        "num_monet_jpg = len(os.listdir('/content/drive/MyDrive/data/monet_jpg'))\n",
        "num_photo_jpg = len(os.listdir('/content/drive/MyDrive/data/photo_jpg'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGbjQ0y7IJyc"
      },
      "source": [
        "\n",
        "Crearea unui DataFrame pentru analiza exploratorie a datelor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pN33KouIKOd",
        "outputId": "a8c28682-04b2-4fd9-ac3a-894f64c935e5"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    'Dataset': ['Monet', 'Photo'],\n",
        "    'TFRecord Images': [num_monet_images, num_photo_images],\n",
        "    'JPG Images': [num_monet_jpg, num_photo_jpg]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Afișarea DataFrame\n",
        "print(\"Summary of Dataset:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELZ_o92WIOQs"
      },
      "source": [
        "Vizualizarea dimensiunii unei imagini din fiecare set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk8m7GrvIOtk",
        "outputId": "7ebf395c-572d-4e6d-b1da-444ec3ed15d3"
      },
      "outputs": [],
      "source": [
        "monet_dataset = tf.data.TFRecordDataset([os.path.join(monet_tfrec_dir, f) for f in os.listdir(monet_tfrec_dir)])\n",
        "photo_dataset = tf.data.TFRecordDataset([os.path.join(photo_tfrec_dir, f) for f in os.listdir(photo_tfrec_dir)])\n",
        "\n",
        "# Aplicarea funcției de decodificare asupra datelor\n",
        "monet_dataset = monet_dataset.map(decode_tfrecord)\n",
        "photo_dataset = photo_dataset.map(decode_tfrecord)\n",
        "\n",
        "# Extragerea unei imagini de exemplu pentru vizualizare\n",
        "sample_monet_image = next(iter(monet_dataset))\n",
        "sample_photo_image = next(iter(photo_dataset))\n",
        "\n",
        "# Afișarea dimensiunilor imaginilor de exemplu\n",
        "print(\"Dimensions of a sample Monet image:\", sample_monet_image.shape)\n",
        "print(\"Dimensions of a sample Photo image:\", sample_photo_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJhhusXVIT55"
      },
      "source": [
        "\n",
        "Vizualizarea a câtorva imagini de exemplu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "ql3vA_ycIUS_",
        "outputId": "47352b41-4353-46c7-b6fe-a4017775c5c1"
      },
      "outputs": [],
      "source": [
        "def visualize_samples(image_dir, num_samples=5):\n",
        "    image_files = os.listdir(image_dir)\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
        "    for i, img_file in enumerate(np.random.choice(image_files, num_samples)):\n",
        "        img = plt.imread(os.path.join(image_dir, img_file))\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Sample Monet paintings:\")\n",
        "visualize_samples('/content/drive/MyDrive/data/monet_jpg')\n",
        "\n",
        "print(\"Sample Photos:\")\n",
        "visualize_samples('/content/drive/MyDrive/data/photo_jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmHC1_CVJ_Da"
      },
      "source": [
        "Calcul histograma culorilor RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD0HUIUqKE9j"
      },
      "outputs": [],
      "source": [
        "def plotImagesHistogram(image_dir):\n",
        "    # Lista pentru a stoca toate imaginile\n",
        "    all_images = []\n",
        "\n",
        "    # Încărcați primele 50 de imagini din director\n",
        "    for img_file in os.listdir(image_dir)[:50]:\n",
        "        img_path = os.path.join(image_dir, img_file)\n",
        "        img = plt.imread(img_path)\n",
        "        all_images.append(img)\n",
        "\n",
        "    # Convertiți lista de imagini într-o matrice numpy\n",
        "    all_images = np.array(all_images)\n",
        "\n",
        "    # Calculează histograma medie pentru fiecare canal de culoare (roșu, verde, albastru)\n",
        "    red_hist = np.mean(all_images[:, :, :, 0], axis=(0, 1))\n",
        "    green_hist = np.mean(all_images[:, :, :, 1], axis=(0, 1))\n",
        "    blue_hist = np.mean(all_images[:, :, :, 2], axis=(0, 1))\n",
        "\n",
        "    # Calculează valorile x pentru linii verticale\n",
        "    x_values = np.arange(256)\n",
        "\n",
        "    # Trasează histograma pentru toate canalele de culoare pe o singură figură\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(x_values, red_hist, color='red', label='Red')\n",
        "    plt.plot(x_values, green_hist, color='green', label='Green')\n",
        "    plt.plot(x_values, blue_hist, color='blue', label='Blue')\n",
        "\n",
        "    plt.title('Average Histogram of RGB Channels')\n",
        "    plt.xlabel('Pixel Intensity')\n",
        "    plt.ylabel('Average Frequency')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOg5zDd_SKfS"
      },
      "source": [
        "Picturi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "U5IvuMVbSLh8",
        "outputId": "c9203228-a0ec-4e07-8774-933c0389fbc7"
      },
      "outputs": [],
      "source": [
        "plotImagesHistogram('/content/drive/MyDrive/data/monet_jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz9GE9brSM-C"
      },
      "source": [
        "Poze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "U0VrXE-tSQn8",
        "outputId": "15a20a3f-0ed9-4ec1-f828-ceea1ec6520f"
      },
      "outputs": [],
      "source": [
        "plotImagesHistogram('/content/drive/MyDrive/data/photo_jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFMG8lbFftlh"
      },
      "source": [
        "# Analiza modelului"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIQD_xzDGIBz"
      },
      "outputs": [],
      "source": [
        "# Root folder\n",
        "root_folder = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_7FVCLGreC0"
      },
      "source": [
        "1. Data Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxjt5Oahf2gt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Function to preprocess images for ResNet50\n",
        "def preprocess_resnet(image):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.keras.applications.resnet50.preprocess_input(image)  # Normalize for ResNet50\n",
        "    return image\n",
        "\n",
        "# Function to preprocess images for GAN\n",
        "def normalize_minus_one_to_one(image):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image / 127.5) - 1.0  # Normalize to [-1, 1]\n",
        "    return image\n",
        "\n",
        "def normalize_zero_to_one(image):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    return image\n",
        "\n",
        "# Function to load images from folder\n",
        "def load_images_from_folder(folder, label, image_size=(256, 256), limit=None):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for i, filename in enumerate(glob.glob(os.path.join(folder, '*.jpg'))):\n",
        "        if limit and i >= limit:\n",
        "            break\n",
        "        img = tf.keras.preprocessing.image.load_img(filename, target_size=image_size)\n",
        "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "# Function to create datasets\n",
        "def create_datasets(monet_folder, photo_folder, test_size=0.2, image_size=(256, 256), batch_size=32,\n",
        "                   monet_limit=None, photo_limit=None):\n",
        "    # Load Monet and photo images for discriminator\n",
        "    monet_images, monet_labels = load_images_from_folder(monet_folder, 0, image_size, limit=monet_limit)  # Label 0 for Monet\n",
        "    print('Successfully loaded Monet images:', len(monet_images))\n",
        "\n",
        "    photo_images, photo_labels = load_images_from_folder(photo_folder, 1, image_size, limit=photo_limit)  # Label 1 for photos\n",
        "    print('Successfully loaded photo images:', len(photo_images))\n",
        "\n",
        "    # Prepare datasets for discriminator training\n",
        "    images = np.array(monet_images + photo_images)\n",
        "    labels = np.array(monet_labels + photo_labels)\n",
        "\n",
        "    train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=test_size)\n",
        "\n",
        "    D_train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "    D_val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "\n",
        "    D_train_dataset = D_train_dataset.map(lambda x, y: (normalize_zero_to_one(x), y)).shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    D_val_dataset = D_val_dataset.map(lambda x, y: (normalize_zero_to_one(x), y)).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Prepare datasets for generator training\n",
        "    photo_images = np.array(photo_images)\n",
        "    dataset_X = tf.data.Dataset.from_tensor_slices(photo_images).map(lambda x: normalize_zero_to_one(x)).shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    monet_images = np.array(monet_images)\n",
        "    dataset_Y = tf.data.Dataset.from_tensor_slices(monet_images).map(lambda x: normalize_zero_to_one(x)).shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset_X, dataset_Y, D_train_dataset, D_val_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkNGlzUOL8bz",
        "outputId": "51bdb682-47b1-42c9-c28a-7941f9e7489a"
      },
      "outputs": [],
      "source": [
        "# Use the create_dataset function with limits\n",
        "dataset_X, dataset_Y, D_train_dataset, D_val_dataset = create_datasets(\n",
        "    monet_folder=root_folder + 'monet_jpg',\n",
        "    photo_folder=root_folder + 'photo_jpg',\n",
        "    batch_size=8,\n",
        "    monet_limit=300,\n",
        "    photo_limit=400\n",
        ")\n",
        "\n",
        "# Print dataset sizes\n",
        "print(\"Generator X to Y training dataset size:\", len(dataset_X))\n",
        "print(\"Generator Y to X training dataset size:\", len(dataset_Y))\n",
        "print(\"Discriminator training dataset size:\", len(D_train_dataset))\n",
        "print(\"Discriminator validation dataset size:\", len(D_val_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdZDA6FCrrvW"
      },
      "source": [
        "2. Build and Fine-tune the Pre-trained Discriminator Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vxVO4I_G6lk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_pretrained_discriminator(pretrained_model):\n",
        "    model = models.Sequential()\n",
        "    model.add(pretrained_model)\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))  # Use sigmoid for binary classification\n",
        "    return model\n",
        "\n",
        "def fine_tune_pretrained_discriminator():\n",
        "    # Load a pre-trained model\n",
        "    pretrained_model = tf.keras.applications.ResNet50(\n",
        "        input_shape=(256, 256, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "\n",
        "    discriminator = build_pretrained_discriminator(pretrained_model)\n",
        "    discriminator.summary()\n",
        "\n",
        "    # Fine-tune the model\n",
        "    discriminator.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    history = discriminator.fit(\n",
        "        D_train_dataset,\n",
        "        validation_data=D_val_dataset,\n",
        "        epochs=10\n",
        "    )\n",
        "\n",
        "    # Save the fine-tuned model\n",
        "    discriminator.save('fine_tuned_discriminator.h5')\n",
        "\n",
        "# fine_tune_pretrained_discriminator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYlqLjKxC7X7"
      },
      "source": [
        "3. Define the Discriminator Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWQ5Xnl7Kpgz",
        "outputId": "6ee9b6bd-1c1a-408d-f59f-d3d406fb6901"
      },
      "outputs": [],
      "source": [
        "# Custom discriminator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D, Flatten, Dense, Input, LeakyReLU, BatchNormalization, GlobalAveragePooling2D, Dropout\n",
        "\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(256, 256, 3)))\n",
        "\n",
        "    model.add(Conv2D(32, (4, 4), strides=2))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(64, (4, 4)))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(128, (4, 4), strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    # model.add(Dropout(0.3))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()\n",
        "\n",
        "# Compile the discriminator\n",
        "# discriminator.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "discriminator.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the discriminator\n",
        "epochs = 70\n",
        "history = discriminator.fit(D_train_dataset, validation_data=D_val_dataset, epochs=epochs, shuffle=True)\n",
        "\n",
        "# Save the discriminator model\n",
        "discriminator.save(root_folder + 'discriminator.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBrt4rT2ZnuH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evalMultiClass(realLabels, computedLabels, labelNames):\n",
        "    confMatrix = confusion_matrix(realLabels, computedLabels)\n",
        "    acc = np.sum([confMatrix[i][i] for i in range(len(labelNames))]) / len(realLabels)\n",
        "    precision = {}\n",
        "    recall = {}\n",
        "    for i in range(len(labelNames)):\n",
        "        precision[labelNames[i]] = confMatrix[i][i] / np.sum([confMatrix[j][i] for j in range(len(labelNames))])\n",
        "        recall[labelNames[i]] = confMatrix[i][i] / np.sum([confMatrix[i][j] for j in range(len(labelNames))])\n",
        "\n",
        "    return acc, precision, recall, confMatrix\n",
        "\n",
        "def plotConfusionMatrix(cm, classNames, title):\n",
        "    classes = classNames\n",
        "    plt.figure()\n",
        "    plt.imshow(cm, interpolation = 'nearest', cmap = 'Blues')\n",
        "    plt.title('Confusion Matrix ' + title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classNames))\n",
        "    plt.xticks(tick_marks, classNames, rotation=45)\n",
        "    plt.yticks(tick_marks, classNames)\n",
        "\n",
        "    text_format = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for row, column in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(column, row, format(cm[row, column], text_format),\n",
        "                horizontalalignment = 'center',\n",
        "                color = 'white' if cm[row, column] > thresh else 'black')\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot the image and prediction\n",
        "def plot_image_and_prediction(image_path, prediction):\n",
        "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(256, 256))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Prediction: {\"Real\" if prediction == 1 else \"Monet\"}')\n",
        "    plt.show()\n",
        "\n",
        "# Plot the training history\n",
        "def plot_training_history(history):\n",
        "    # Plot the loss\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    \n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "Glz4JdC0kOPL",
        "outputId": "f69f82c9-3f74-4f36-9eb7-f7823521f001"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Call the function to plot the training history\n",
        "plot_training_history(history)\n",
        "\n",
        "results = discriminator.predict(D_val_dataset)\n",
        "\n",
        "computed = [0 if x < 0.5 else 1 for x in results]\n",
        "real = np.concatenate(([el2 for el1, el2 in list(D_val_dataset.as_numpy_iterator())]), axis=None).tolist()\n",
        "\n",
        "acc, prec, recall, cm = evalMultiClass(real, computed, ['Monet', 'Photo'])\n",
        "print('Accuracy:', acc)\n",
        "print('Precision:', prec)\n",
        "print('Recall:', recall)\n",
        "plotConfusionMatrix(cm, ['Monet', 'Photo'], 'Discriminator')\n",
        "\n",
        "# Load the fine-tuned discriminator model\n",
        "# discriminator = tf.keras.models.load_model(root_folder + 'discriminator.h5')\n",
        "\n",
        "# Test images\n",
        "test_image_paths = [\n",
        "    root_folder + 'photo_jpg/0a74701f65.jpg',\n",
        "    root_folder + 'monet_jpg/2f20944b6a.jpg',\n",
        "    root_folder + 'photo_jpg/0aec1f9701.jpg',\n",
        "    root_folder + 'monet_jpg/32e33792cc.jpg'\n",
        "]\n",
        "\n",
        "# Predict and plot results\n",
        "for image_path in test_image_paths:\n",
        "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(256, 256))\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image = normalize_zero_to_one(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    prediction = discriminator.predict(image)\n",
        "    print(f'Prediction: {prediction}')\n",
        "    prediction = round(prediction[0][0])\n",
        "    plot_image_and_prediction(image_path, prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQvpmJ-jrhlz"
      },
      "source": [
        "4. Define the Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F4MD5ktG4-b",
        "outputId": "77e342b8-c71e-4114-8668-2881df18a140"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# # Define generator model\n",
        "# generator = models.Sequential([\n",
        "#     layers.Input(shape=(256, 256, 3)),\n",
        "#     layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "#     layers.BatchNormalization(),\n",
        "#     layers.Conv2D(3, kernel_size=(3, 3), padding='same', activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# generator.summary()\n",
        "# generator.compile()\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def residual_block(x, filters, kernel_size=3, strides=1):\n",
        "    res = x\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Add()([x, res])\n",
        "    return x\n",
        "\n",
        "def build_generator(input_shape=(256, 256, 3)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    down1 = layers.Conv2D(64, (3, 3), strides=2, padding='same')(inputs)\n",
        "    down1 = layers.BatchNormalization()(down1)\n",
        "    down1 = layers.ReLU()(down1)\n",
        "\n",
        "    down2 = layers.Conv2D(128, (3, 3), strides=2, padding='same')(down1)\n",
        "    down2 = layers.BatchNormalization()(down2)\n",
        "    down2 = layers.ReLU()(down2)\n",
        "\n",
        "    down3 = layers.Conv2D(256, (3, 3), strides=2, padding='same')(down2)\n",
        "    down3 = layers.BatchNormalization()(down3)\n",
        "    down3 = layers.ReLU()(down3)\n",
        "\n",
        "    # Bottleneck with More Residual Blocks\n",
        "    bottleneck = residual_block(down3, 256)\n",
        "    bottleneck = residual_block(bottleneck, 256)\n",
        "    bottleneck = residual_block(bottleneck, 256)\n",
        "    bottleneck = residual_block(bottleneck, 256)\n",
        "    bottleneck = residual_block(bottleneck, 256)\n",
        "\n",
        "    # Decoder\n",
        "    up3 = layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same')(bottleneck)\n",
        "    up3 = layers.BatchNormalization()(up3)\n",
        "    up3 = layers.ReLU()(up3)\n",
        "\n",
        "    up2 = layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same')(up3)\n",
        "    up2 = layers.BatchNormalization()(up2)\n",
        "    up2 = layers.ReLU()(up2)\n",
        "\n",
        "    up1 = layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same')(up2)\n",
        "    up1 = layers.BatchNormalization()(up1)\n",
        "    up1 = layers.ReLU()(up1)\n",
        "\n",
        "    outputs = layers.Conv2D(3, (3, 3), padding='same', activation='sigmoid')(up1)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.summary()\n",
        "    model.compile()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5.0 Define and train the Cycle-GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Plotting generated images for a sample array of images\n",
        "def display_generated_images(title, generator, images):\n",
        "    num_images = len(images)\n",
        "    plt.figure(figsize=(20, 10))  # Increase figure size\n",
        "\n",
        "    for i, image in enumerate(images):\n",
        "        image = np.expand_dims(image, axis=0)  # Add an extra dimension\n",
        "        generated_image = generator(image, training=False)\n",
        "        generated_image = generated_image[0] / 1.0\n",
        "        image = image[0] / 1.0\n",
        "\n",
        "        plt.subplot(2, num_images, i + 1)  # Adjust subplot for horizontal layout\n",
        "        plt.imshow(image)\n",
        "        plt.title(f'Original Image {i+1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(2, num_images, i + num_images + 1)  # Adjust subplot for horizontal layout\n",
        "        plt.imshow(generated_image)\n",
        "        plt.title(f'Generated Image {i+1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plotting the losses\n",
        "def plot_losses(gen_x_losses, disc_y_losses, batch_gen_x_losses, batch_disc_y_losses,\n",
        "                 gen_y_losses, disc_x_losses, batch_gen_y_losses, batch_disc_x_losses):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot losses per epoch\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(gen_x_losses, label='Generator XtoY Loss per Epoch')\n",
        "    plt.plot(disc_y_losses, label='Discriminator Y Loss per Epoch')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss per Epoch')\n",
        "\n",
        "    # Plot losses per batch\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(batch_gen_x_losses, label='Generator XtoY Loss per Batch')\n",
        "    plt.plot(batch_disc_y_losses, label='Discriminator Y Loss per Batch')\n",
        "    plt.xlabel('Batches')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss per Batch')\n",
        "\n",
        "    # Plot losses per epoch\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(gen_y_losses, label='Generator YtoX Loss per Epoch')\n",
        "    plt.plot(disc_x_losses, label='Discriminator X Loss per Epoch')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss per Epoch')\n",
        "\n",
        "    # Plot losses per batch\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(batch_gen_y_losses, label='Generator YtoX Loss per Batch')\n",
        "    plt.plot(batch_disc_x_losses, label='Discriminator X Loss per Batch')\n",
        "    plt.xlabel('Batches')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss per Batch')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load/build the generators and discriminators\n",
        "G_XtoY = build_generator()\n",
        "G_YtoX = build_generator()\n",
        "D_X = tf.keras.models.load_model(root_folder + 'discriminator.h5')\n",
        "D_Y = tf.keras.models.load_model(root_folder + 'discriminator.h5')\n",
        "# print(\"Model(s) loaded successfully\")\n",
        "\n",
        "# Define loss functions\n",
        "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "def discriminator_loss(real, generated):\n",
        "    real_loss = loss_obj(tf.ones_like(real), real)\n",
        "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
        "    return real_loss + generated_loss\n",
        "\n",
        "def generator_loss(generated):\n",
        "    return loss_obj(tf.ones_like(generated), generated)\n",
        "\n",
        "def cycle_loss(real_image, cycled_image, lambda_cycle):\n",
        "    loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "    return lambda_cycle * loss\n",
        "\n",
        "def identity_loss(real_image, same_image, lambda_identity):\n",
        "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "    return lambda_identity * loss\n",
        "\n",
        "# Define optimizers\n",
        "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "# Define generator and discriminator losses arrays\n",
        "gen_g_losses, gen_f_losses, disc_x_losses, disc_y_losses = [], [], [], []\n",
        "batch_gen_g_losses, batch_gen_f_losses, batch_disc_x_losses, batch_disc_y_losses = [], [], [], []\n",
        "\n",
        "# Train the models while collecting the losses\n",
        "@tf.function\n",
        "def train_step_with_loss_collection(real_x, real_y, lambda_cycle=10, lambda_identity=0.5):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # Generate fake images\n",
        "        fake_y = G_XtoY(real_x, training=True)\n",
        "        cycled_x = G_YtoX(fake_y, training=True)\n",
        "        \n",
        "        fake_x = G_YtoX(real_y, training=True)\n",
        "        cycled_y = G_XtoY(fake_x, training=True)\n",
        "        \n",
        "        # Identity mapping\n",
        "        same_x = G_YtoX(real_x, training=True)\n",
        "        same_y = G_XtoY(real_y, training=True)\n",
        "        \n",
        "        # Discriminator output\n",
        "        disc_real_x = D_X(real_x, training=True)\n",
        "        disc_fake_x = D_X(fake_x, training=True)\n",
        "        \n",
        "        disc_real_y = D_Y(real_y, training=True)\n",
        "        disc_fake_y = D_Y(fake_y, training=True)\n",
        "        \n",
        "        # Calculate the losses\n",
        "        gen_g_loss = generator_loss(disc_fake_y)\n",
        "        gen_f_loss = generator_loss(disc_fake_x)\n",
        "        \n",
        "        total_cycle_loss = cycle_loss(real_x, cycled_x, lambda_cycle) + cycle_loss(real_y, cycled_y, lambda_cycle)\n",
        "        \n",
        "        total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y, lambda_identity)\n",
        "        total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x, lambda_identity)\n",
        "        \n",
        "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
        "        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
        "    \n",
        "    # Calculate the gradients\n",
        "    gradients_of_gen_g = tape.gradient(total_gen_g_loss, G_XtoY.trainable_variables)\n",
        "    gradients_of_gen_f = tape.gradient(total_gen_f_loss, G_YtoX.trainable_variables)\n",
        "    \n",
        "    gradients_of_disc_x = tape.gradient(disc_x_loss, D_X.trainable_variables)\n",
        "    gradients_of_disc_y = tape.gradient(disc_y_loss, D_Y.trainable_variables)\n",
        "    \n",
        "    # Apply the gradients\n",
        "    generator_g_optimizer.apply_gradients(zip(gradients_of_gen_g, G_XtoY.trainable_variables))\n",
        "    generator_f_optimizer.apply_gradients(zip(gradients_of_gen_f, G_YtoX.trainable_variables))\n",
        "    \n",
        "    discriminator_x_optimizer.apply_gradients(zip(gradients_of_disc_x, D_X.trainable_variables))\n",
        "    discriminator_y_optimizer.apply_gradients(zip(gradients_of_disc_y, D_Y.trainable_variables))\n",
        "    \n",
        "    return total_gen_g_loss, total_gen_f_loss, disc_x_loss, disc_y_loss\n",
        "\n",
        "# Train the models while collecting the losses\n",
        "def train_with_loss_collection(dataset_x, dataset_y, epochs):\n",
        "    num_images = 5\n",
        "    sample_images_x = next(iter(dataset_X))[:num_images]\n",
        "    sample_images_y = next(iter(dataset_Y))[:num_images]\n",
        "\n",
        "    print('dataset_X size:', len(dataset_X), 'dataset_Y size:', len(dataset_Y))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_gen_g_loss, epoch_gen_f_loss = 0, 0\n",
        "        epoch_disc_x_loss, epoch_disc_y_loss = 0, 0\n",
        "\n",
        "        epoch_batches = min(len(dataset_X), len(dataset_Y))\n",
        "\n",
        "        # Shuffle the datasets\n",
        "        dataset_X.shuffle(buffer_size=1000)\n",
        "        dataset_Y.shuffle(buffer_size=1000)\n",
        "        \n",
        "        for i, (image_batch_x, image_batch_y) in enumerate(zip(dataset_x, dataset_y)):\n",
        "            gen_g_loss, gen_f_loss, disc_x_loss, disc_y_loss = train_step_with_loss_collection(image_batch_x, image_batch_y)\n",
        "\n",
        "            # Print the losses\n",
        "            print(f'Batch {i + 1}/{epoch_batches}: Generator G Loss: {gen_g_loss}, Discriminator Y Loss: {disc_y_loss}, '\n",
        "                  f'Generator F Loss: {gen_f_loss}, Discriminator X Loss: {disc_x_loss}')\n",
        "            \n",
        "            epoch_gen_g_loss += gen_g_loss\n",
        "            epoch_gen_f_loss += gen_f_loss\n",
        "            epoch_disc_x_loss += disc_x_loss\n",
        "            epoch_disc_y_loss += disc_y_loss\n",
        "\n",
        "            # Append the batch losses\n",
        "            batch_gen_g_losses.append(gen_g_loss)\n",
        "            batch_gen_f_losses.append(gen_f_loss)\n",
        "            batch_disc_x_losses.append(disc_x_loss)\n",
        "            batch_disc_y_losses.append(disc_y_loss)\n",
        "\n",
        "        epoch_gen_g_loss /= epoch_batches\n",
        "        epoch_gen_f_loss /= epoch_batches\n",
        "        epoch_disc_x_loss /= epoch_batches\n",
        "        epoch_disc_y_loss /= epoch_batches\n",
        "\n",
        "        gen_g_losses.append(epoch_gen_g_loss)\n",
        "        gen_f_losses.append(epoch_gen_f_loss)\n",
        "        disc_x_losses.append(epoch_disc_x_loss)\n",
        "        disc_y_losses.append(epoch_disc_y_loss)\n",
        "        \n",
        "        print(f'Epoch {epoch+1}/{epochs}, '\n",
        "              f'Generator G Loss: {epoch_gen_g_loss}, Discriminator Y Loss: {epoch_disc_y_loss}, '\n",
        "              f'Generator F Loss: {epoch_gen_f_loss}, Discriminator X Loss: {epoch_disc_x_loss}')\n",
        "        \n",
        "        display_generated_images(f'XtoY: Epoch {epoch + 1}', G_XtoY, sample_images_x)\n",
        "        display_generated_images(f'YtoX: Epoch {epoch + 1}', G_YtoX, sample_images_y)\n",
        "        \n",
        "    # Save models\n",
        "    G_XtoY.save(root_folder + 'generator_g.h5')\n",
        "    G_YtoX.save(root_folder + 'generator_f.h5')\n",
        "    D_X.save(root_folder + 'discriminator_x.h5')\n",
        "    D_Y.save(root_folder + 'discriminator_y.h5')\n",
        "\n",
        "\n",
        "train_with_loss_collection(dataset_X, dataset_Y, epochs=50)\n",
        "\n",
        "# Plot the losses\n",
        "plot_losses(gen_g_losses, gen_f_losses, batch_gen_g_losses, batch_disc_y_losses,\n",
        "            gen_f_losses, disc_x_losses, batch_gen_f_losses, batch_disc_x_losses)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP_ZF7-hr3eB"
      },
      "source": [
        "5. Define and train the GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouilWuVR1dxY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pZTknZ0EeVDP",
        "outputId": "b43dc9cd-548e-457e-9697-aaca7c655ea7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Assuming generator and discriminator are already defined and compiled\n",
        "discriminator = tf.keras.models.load_model(root_folder + 'discriminator.h5')\n",
        "# generator = tf.keras.models.load_model(root_folder + 'generator.h5')\n",
        "# print(\"Model(s) loaded successfully\")\n",
        "\n",
        "# Define loss function\n",
        "binary_crossentropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "# Define optimizers\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "\n",
        "# Function to store loss values\n",
        "gen_losses, disc_losses, batch_gen_losses, batch_disc_losses = [], [], [], []\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(real_images, training=True)\n",
        "\n",
        "        real_output = discriminator(real_images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = binary_crossentropy(tf.ones_like(fake_output), fake_output)\n",
        "        disc_loss_real = binary_crossentropy(tf.ones_like(real_output), real_output)\n",
        "        disc_loss_fake = binary_crossentropy(tf.zeros_like(fake_output), fake_output)\n",
        "        disc_loss = disc_loss_real + disc_loss_fake\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    num_images = 5\n",
        "    sample_images = next(iter(dataset_X))[:num_images]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        total_gen_loss = 0\n",
        "        total_disc_loss = 0\n",
        "        for image_batch in dataset:\n",
        "            i += 1\n",
        "            gen_loss, disc_loss = train_step(image_batch)\n",
        "            print(f'Batch {i}/{len(dataset)}: Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}')\n",
        "            total_gen_loss += gen_loss\n",
        "            total_disc_loss += disc_loss\n",
        "\n",
        "            # Store batch losses\n",
        "            batch_gen_losses.append(gen_loss.numpy())\n",
        "            batch_disc_losses.append(disc_loss.numpy())\n",
        "\n",
        "        epoch_gen_loss = total_gen_loss / i\n",
        "        epoch_disc_loss = total_disc_loss / i\n",
        "\n",
        "        print(f'Epoch: {epoch+1}, Overall Generator Loss: {epoch_gen_loss}, Overall Discriminator Loss: {epoch_disc_loss}')\n",
        "        gen_losses.append(epoch_gen_loss.numpy())\n",
        "        disc_losses.append(epoch_disc_loss.numpy())\n",
        "\n",
        "        display_generated_images(f'Epoch {epoch + 1}', generator, sample_images)\n",
        "\n",
        "# Train the GAN\n",
        "train(dataset_X, epochs=150)\n",
        "\n",
        "# Call the function to plot the losses\n",
        "plot_losses(gen_losses, disc_losses, batch_gen_losses, batch_disc_losses)\n",
        "\n",
        "# Save the trained generator model\n",
        "generator.save(root_folder + 'generator.h5')\n",
        "\n",
        "# Save the updated discriminator model\n",
        "discriminator.save(root_folder + 'updated_discriminator.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOzIhBs4mTsQ"
      },
      "source": [
        "6. Re-load the GAN and test it with a small set of photos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7qOHYwqmg3o",
        "outputId": "bb374453-5e4a-4937-9a4e-58d55b03d752"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "generator = load_model(root_folder + 'generator_g.h5')\n",
        "\n",
        "generator.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VHfom5f-mhYw",
        "outputId": "cea7609d-c71d-43a7-eed8-1975e0a050ef"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "def transform_and_save_images(generator, test_image_paths, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    test_images = []\n",
        "\n",
        "    for i, path in enumerate(test_image_paths):\n",
        "        test_image = tf.keras.preprocessing.image.load_img(path, target_size=(256, 256))\n",
        "        test_image = tf.keras.preprocessing.image.img_to_array(test_image)\n",
        "        test_image = normalize_zero_to_one(test_image)\n",
        "        test_images.append(test_image)\n",
        "\n",
        "    display_generated_images('Test Images', generator, test_images)\n",
        "\n",
        "# Example usage\n",
        "test_image_paths = [\n",
        "    root_folder + 'photo_jpg/0f8e316a87.jpg',\n",
        "    root_folder + 'photo_jpg/0039ebb598.jpg'\n",
        "]\n",
        "output_folder = root_folder + 'generated_paintings/'\n",
        "\n",
        "transform_and_save_images(generator, test_image_paths, output_folder)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "d9OVMuEmaT1K"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
